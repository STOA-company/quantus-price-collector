import logging
import json
import time
from typing import Dict, Any
from kafka import KafkaProducer
import os
from datetime import datetime

logger = logging.getLogger(__name__)

class KafkaService:
    def __init__(self):
        self.producer = None
        self.bootstrap_servers = os.getenv('KAFKA_BROKERS', 'localhost:19092,localhost:29092,localhost:39092').split(',')
        self.topic_prefix = 'stock_prices'
        self._is_connected = False
        
        self._last_publish_time: Dict[str, float] = {}  # ì¢…ëª©ë³„ ë§ˆì§€ë§‰ ë°œì†¡ ì‹œê°„
        self._throttle_interval = 0.5  # 0.5ì´ˆ ê°„ê²© (Redisì™€ ë™ì¼)
        
        # ğŸ”¥ ì´ˆê¸° ì—°ê²° ì‹œë„
        self.connect()
    
    def connect(self):
        """Kafka Producer ì—°ê²°"""
        try:
            if self.producer:
                self.producer.close()
            
            self.producer = KafkaProducer(
                bootstrap_servers=self.bootstrap_servers,
                value_serializer=lambda v: json.dumps(self._serialize_data(v)).encode('utf-8'),
                key_serializer=lambda k: k.encode('utf-8') if k else None,
                security_protocol=os.getenv('KAFKA_SECURITY_PROTOCOL', 'PLAINTEXT')
            )
            self._is_connected = True
            logger.info(f"âœ… Kafka Producer ì—°ê²° ì„±ê³µ: {self.bootstrap_servers}")
            return True
        except Exception as e:
            logger.error(f"âŒ Kafka Producer ì—°ê²° ì‹¤íŒ¨: {e}")
            self._is_connected = False
            return False
    
    # ï¿½ï¿½ disconnect ë©”ì„œë“œ ì¶”ê°€
    def disconnect(self):
        """Kafka Producer ì—°ê²° í•´ì œ"""
        try:
            if self.producer:
                self.producer.close()
                self.producer = None
                self._is_connected = False
                logger.info("âœ… Kafka Producer ì—°ê²° í•´ì œ")
        except Exception as e:
            logger.error(f"âŒ Kafka Producer ì—°ê²° í•´ì œ ì‹¤íŒ¨: {e}")
    
    def close(self):
        """disconnectì˜ ë³„ì¹­"""
        self.disconnect()
    
    def is_connected(self) -> bool:
        """ì—°ê²° ìƒíƒœ í™•ì¸"""
        try:
            if self.producer:
                # ê°„ë‹¨í•œ ë©”íƒ€ë°ì´í„° ì¡°íšŒë¡œ ì—°ê²° ìƒíƒœ í™•ì¸
                self.producer.metrics()
                return True
        except Exception:
            self._is_connected = False
        return self._is_connected
    
    def reconnect(self) -> bool:
        """ì¬ì—°ê²° ì‹œë„"""
        try:
            if self.producer:
                self.producer.close()
            self._connect()
            return self._is_connected
        except Exception as e:
            logger.error(f"âŒ Kafka ì¬ì—°ê²° ì‹¤íŒ¨: {e}")
            return False

    def publish_raw_data(self, broker_name: str, data: Dict[str, Any]) -> bool:
        """ì›ë³¸ ë°ì´í„°ë¥¼ Kafkaì— ë°œí–‰ (Redisì™€ ë™ì¼í•œ ì“°ë¡œí‹€ë§ ì ìš©)"""
        try:
            if not self.producer:
                return False
            
            symbol = data.get('symbol', 'unknown')
            current_time = time.time()
            
            # ğŸ”¥ Redisì™€ ë™ì¼í•œ Throttling ì²´í¬: ê°™ì€ ì¢…ëª©ì— ëŒ€í•´ 0.5ì´ˆ ì´ë‚´ ë°œì†¡ ì œí•œ
            last_time = self._last_publish_time.get(symbol, 0)
            if current_time - last_time < self._throttle_interval:
                # logger.debug(f"Throttling: {symbol} ë°ì´í„° ë°œì†¡ ìŠ¤í‚µ (ë§ˆì§€ë§‰ ë°œì†¡: {current_time - last_time:.2f}ì´ˆ ì „)")
                return False
            
            # í† í”½ëª… ìƒì„±
            topic = f"{symbol}_raw_data"
            
            # í‚¤ëŠ” ë¸Œë¡œì»¤ëª…, ê°’ì€ ë°ì´í„°
            future = self.producer.send(
                topic=topic,
                key=broker_name,
                value=data
            )
            
            # ë¹„ë™ê¸° ë°œí–‰ ê²°ê³¼ í™•ì¸
            record_metadata = future.get(timeout=10)
            
            # ï¿½ï¿½ ë°œì†¡ ì‹œê°„ ê¸°ë¡ (Redisì™€ ë™ì¼)
            self._last_publish_time[symbol] = current_time
            
            logger.debug(f"ğŸ“¨ Kafka ë°œí–‰ ì„±ê³µ: {topic} (íŒŒí‹°ì…˜: {record_metadata.partition}, ì˜¤í”„ì…‹: {record_metadata.offset})")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Kafka ë°œí–‰ ì˜¤ë¥˜: {e}")
            return False
    
    def publish_broker_status(self, broker_name: str, status_data: Dict[str, Any]) -> bool:
        """ë¸Œë¡œì»¤ ìƒíƒœë¥¼ Kafkaì— ë°œí–‰ (Redisì™€ ë™ì¼í•œ í˜•íƒœ)"""
        try:
            if not self.is_connected():
                return False
            
            # ï¿½ï¿½ Redisì™€ ë™ì¼í•œ í† í”½ëª… ìƒì„±
            topic = f"broker_{broker_name}_status"  # "broker:dbfi:status" í˜•íƒœ
            
            future = self.producer.send(
                topic=topic,
                key=broker_name,
                value=status_data
            )
            
            record_metadata = future.get(timeout=10)
            logger.debug(f"ë¸Œë¡œì»¤ ìƒíƒœ ë°œí–‰: {broker_name}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ë¸Œë¡œì»¤ ìƒíƒœ ë°œí–‰ ì˜¤ë¥˜: {e}")
            return False
    def _serialize_data(self, data: Any) -> str:
        """ë°ì´í„°ë¥¼ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜"""
        if isinstance(data, dict):
            return {k: self._serialize_data(v) for k, v in data.items()}
        elif isinstance(data, list):
            return [self._serialize_data(item) for item in data]
        elif isinstance(data, datetime):
            return data.isoformat()
        elif hasattr(data, 'isoformat'):  # date ê°ì²´ ë“±
            return data.isoformat()
        else:
            return data